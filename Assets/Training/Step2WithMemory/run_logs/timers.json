{
    "name": "root",
    "gauges": {
        "AgentBehavior.Policy.Entropy.mean": {
            "value": 1.3452210426330566,
            "min": 1.3442206382751465,
            "max": 1.461983561515808,
            "count": 154
        },
        "AgentBehavior.Policy.Entropy.sum": {
            "value": 13602.875,
            "min": 12744.513671875,
            "max": 19044.142578125,
            "count": 154
        },
        "AgentBehavior.Environment.EpisodeLength.mean": {
            "value": 41.02978723404255,
            "min": 25.078034682080926,
            "max": 152.07070707070707,
            "count": 154
        },
        "AgentBehavior.Environment.EpisodeLength.sum": {
            "value": 9642.0,
            "min": 5589.0,
            "max": 17535.0,
            "count": 154
        },
        "AgentBehavior.Step.mean": {
            "value": 1539944.0,
            "min": 9972.0,
            "max": 1539944.0,
            "count": 154
        },
        "AgentBehavior.Step.sum": {
            "value": 1539944.0,
            "min": 9972.0,
            "max": 1539944.0,
            "count": 154
        },
        "AgentBehavior.Policy.ExtrinsicValueEstimate.mean": {
            "value": 11.49634075164795,
            "min": 3.1887998580932617,
            "max": 11.5298433303833,
            "count": 154
        },
        "AgentBehavior.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3184.486328125,
            "min": 790.8223876953125,
            "max": 3281.35302734375,
            "count": 154
        },
        "AgentBehavior.Environment.CumulativeReward.mean": {
            "value": 14.415254369630652,
            "min": 3.665128029882908,
            "max": 15.08955162282482,
            "count": 154
        },
        "AgentBehavior.Environment.CumulativeReward.sum": {
            "value": 3402.000031232834,
            "min": 707.1580132246017,
            "max": 3516.3340451717377,
            "count": 154
        },
        "AgentBehavior.Policy.ExtrinsicReward.mean": {
            "value": 14.415254369630652,
            "min": 3.665128029882908,
            "max": 15.08955162282482,
            "count": 154
        },
        "AgentBehavior.Policy.ExtrinsicReward.sum": {
            "value": 3402.000031232834,
            "min": 707.1580132246017,
            "max": 3516.3340451717377,
            "count": 154
        },
        "AgentBehavior.Losses.PolicyLoss.mean": {
            "value": 0.20068251030243117,
            "min": 0.11118633116323812,
            "max": 0.45400299907972413,
            "count": 154
        },
        "AgentBehavior.Losses.PolicyLoss.sum": {
            "value": 0.40136502060486234,
            "min": 0.11679151511440675,
            "max": 0.9080059981594483,
            "count": 154
        },
        "AgentBehavior.Losses.ValueLoss.mean": {
            "value": 3.2453846484422684,
            "min": 2.16709366440773,
            "max": 51.162650760014856,
            "count": 154
        },
        "AgentBehavior.Losses.ValueLoss.sum": {
            "value": 6.490769296884537,
            "min": 2.5260942141215006,
            "max": 102.32530152002971,
            "count": 154
        },
        "AgentBehavior.Policy.LearningRate.mean": {
            "value": 6.977797674070002e-05,
            "min": 6.977797674070002e-05,
            "max": 0.0002991006752997749,
            "count": 154
        },
        "AgentBehavior.Policy.LearningRate.sum": {
            "value": 0.00013955595348140004,
            "min": 7.28313757229e-05,
            "max": 0.0005982013505995499,
            "count": 154
        },
        "AgentBehavior.Policy.Epsilon.mean": {
            "value": 0.1232593,
            "min": 0.1232593,
            "max": 0.199700225,
            "count": 154
        },
        "AgentBehavior.Policy.Epsilon.sum": {
            "value": 0.2465186,
            "min": 0.1242771,
            "max": 0.39940045,
            "count": 154
        },
        "AgentBehavior.Policy.Beta.mean": {
            "value": 0.00117063907,
            "min": 0.00117063907,
            "max": 0.004985041227499999,
            "count": 154
        },
        "AgentBehavior.Policy.Beta.sum": {
            "value": 0.00234127814,
            "min": 0.00122142729,
            "max": 0.009970082454999998,
            "count": 154
        },
        "AgentBehavior.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 154
        },
        "AgentBehavior.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 154
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1770154504",
        "python_version": "3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]",
        "command_line_arguments": "/home/ale/unity-projects/Dungeon Escape/venv/bin/mlagents-learn Assets/Config/config.yaml --run-id Step2WithMemory --results-dir Assets/Training/ --force --initialize-from Step1WithMemory",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.8.0+cu128",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1770155660"
    },
    "total": 1156.9037141790004,
    "count": 1,
    "self": 0.002205534000040643,
    "children": {
        "run_training.setup": {
            "total": 0.01096652800015363,
            "count": 1,
            "self": 0.01096652800015363
        },
        "TrainerController.start_learning": {
            "total": 1156.8905421170002,
            "count": 1,
            "self": 0.27495172301223647,
            "children": {
                "TrainerController._reset_env": {
                    "total": 4.972791800000323,
                    "count": 1,
                    "self": 4.972791800000323
                },
                "TrainerController.advance": {
                    "total": 1151.608417001988,
                    "count": 26212,
                    "self": 0.23895276095754525,
                    "children": {
                        "env_step": {
                            "total": 1008.1214678720071,
                            "count": 26212,
                            "self": 991.7997717949788,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 16.160816112982502,
                                    "count": 26212,
                                    "self": 1.177338781983508,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 14.983477330998994,
                                            "count": 12064,
                                            "self": 14.983477330998994
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.16087996404576188,
                                    "count": 26211,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1156.3309143120086,
                                            "count": 26211,
                                            "is_parallel": true,
                                            "self": 203.94717220706934,
                                            "children": {
                                                "run_training.setup": {
                                                    "total": 0.0,
                                                    "count": 0,
                                                    "is_parallel": true,
                                                    "self": 0.0,
                                                    "children": {
                                                        "steps_from_proto": {
                                                            "total": 0.0014967659999456373,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.00030193900056474376,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 0.0011948269993808935,
                                                                    "count": 4,
                                                                    "is_parallel": true,
                                                                    "self": 0.0011948269993808935
                                                                }
                                                            }
                                                        },
                                                        "UnityEnvironment.step": {
                                                            "total": 0.4700970110002345,
                                                            "count": 1,
                                                            "is_parallel": true,
                                                            "self": 0.0005359479996513983,
                                                            "children": {
                                                                "UnityEnvironment._generate_step_input": {
                                                                    "total": 0.001123017000281834,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.001123017000281834
                                                                },
                                                                "communicator.exchange": {
                                                                    "total": 0.467283549000058,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.467283549000058
                                                                },
                                                                "steps_from_proto": {
                                                                    "total": 0.001154497000243282,
                                                                    "count": 1,
                                                                    "is_parallel": true,
                                                                    "self": 0.00019845999986500829,
                                                                    "children": {
                                                                        "_process_rank_one_or_two_observation": {
                                                                            "total": 0.0009560370003782737,
                                                                            "count": 4,
                                                                            "is_parallel": true,
                                                                            "self": 0.0009560370003782737
                                                                        }
                                                                    }
                                                                }
                                                            }
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 952.3837421049393,
                                                    "count": 26210,
                                                    "is_parallel": true,
                                                    "self": 5.408297910940746,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 9.430225023944786,
                                                            "count": 26210,
                                                            "is_parallel": true,
                                                            "self": 9.430225023944786
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 923.8092945940148,
                                                            "count": 26210,
                                                            "is_parallel": true,
                                                            "self": 923.8092945940148
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 13.735924576038997,
                                                            "count": 26210,
                                                            "is_parallel": true,
                                                            "self": 2.3714687800529646,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 11.364455795986032,
                                                                    "count": 104840,
                                                                    "is_parallel": true,
                                                                    "self": 11.364455795986032
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 143.24799636902344,
                            "count": 26211,
                            "self": 0.7298841409979104,
                            "children": {
                                "process_trajectory": {
                                    "total": 93.01160433502764,
                                    "count": 26211,
                                    "self": 92.89806021302775,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.11354412199989383,
                                            "count": 3,
                                            "self": 0.11354412199989383
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 49.50650789299789,
                                    "count": 230,
                                    "self": 9.212989606976407,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 40.29351828602148,
                                            "count": 6900,
                                            "self": 40.29351828602148
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 6.099999154685065e-07,
                    "count": 1,
                    "self": 6.099999154685065e-07
                },
                "TrainerController._save_models": {
                    "total": 0.03438098199967499,
                    "count": 1,
                    "self": 0.0004998309996153694,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.03388115100005962,
                            "count": 1,
                            "self": 0.03388115100005962
                        }
                    }
                }
            }
        }
    }
}